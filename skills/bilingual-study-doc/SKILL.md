---
name: bilingual-study-doc
description: |
  Create bilingual (English-Chinese) study documents from English periodicals, magazines, or articles.
  Use when user uploads PDF/document files of English publications (The Economist, Time, The Atlantic, 
  Harvard Business Review, Scientific American, etc.) and wants to create study materials.
  
  Triggers: "ç¿»è¯‘", "åŒè¯­", "å­¦ä¹ ", "å¯¹ç…§", "bilingual", "study document", "å­¦è‹±è¯­", "è‹±è¯­å­¦ä¹ ",
  "å¸®æˆ‘ç¿»è¯‘è¿™ç¯‡æ–‡ç« ", "åˆ›å»ºå­¦ä¹ æ–‡æ¡£", "æå–æ–‡ç« å¹¶ç¿»è¯‘", "é€‰å‡ ç¯‡æ–‡ç« "
  
  Output: Markdown file with paragraph-by-paragraph English-Chinese alignment, plus vocabulary lists 
  with example sentences for language learning.
---

# Bilingual Study Document Generator

Create professional bilingual study documents from English periodicals for language learning.

## Workflow

### Step 1: Extract Content from Source

```python
import pdfplumber

def extract_pdf_text(pdf_path):
    """Extract text from PDF, preserving structure"""
    all_pages = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                all_pages.append(text)
    return '\n\n'.join(all_pages)
```

For PDF files, use `pdfplumber` (install: `pip install pdfplumber --break-system-packages`).

### Step 2: Identify Article Boundaries

Common patterns for article separation:
- URL markers: `This article was downloaded from...`
- Section headers: `Leaders`, `Business`, `Culture`, etc.
- Date lines: `January 22nd 2026`
- Bylines and author credits

```python
import re

def split_articles(full_text, separator_pattern):
    """Split text into individual articles"""
    # Example for Economist-style documents
    pattern = r'This article was downloaded by.*?from (https://[^\n]+)'
    matches = list(re.finditer(pattern, full_text))
    
    articles = []
    for i, match in enumerate(matches):
        start = matches[i-1].end() if i > 0 else 0
        end = match.start()
        content = full_text[start:end].strip()
        url = match.group(1)
        articles.append({'content': content, 'url': url})
    return articles
```

### Step 3: Clean and Format Paragraphs

PDF extraction often breaks paragraphs at line endings. Fix this:

```python
def fix_paragraphs(text):
    """Merge lines broken by PDF extraction into proper paragraphs"""
    lines = text.split('\n')
    result = []
    current_para = []
    
    for line in lines:
        line = line.strip()
        if not line:
            if current_para:
                result.append(' '.join(current_para))
                current_para = []
        else:
            # Handle hyphenated words at line breaks
            if current_para and current_para[-1].endswith('-'):
                current_para[-1] = current_para[-1][:-1] + line
            else:
                current_para.append(line)
    
    if current_para:
        result.append(' '.join(current_para))
    return result
```

### Step 4: Generate Bilingual Markdown

Use this output structure:

```markdown
# [Publication Name] [Issue Date]

> **å­¦ä¹ æŒ‡å— | Study Guide**
> æ ¼å¼ï¼šè‹±æ–‡åŽŸæ–‡ï¼ˆå¼•ç”¨å—ï¼‰åŽç´§è·Ÿä¸­æ–‡ç¿»è¯‘

---

## [Article Title]
## [ä¸­æ–‡æ ‡é¢˜]

**[Section] | [åˆ†ç±»]**  
*[Subtitle]*  
*[å‰¯æ ‡é¢˜ç¿»è¯‘]*

ðŸ“… [Date]

---

> [English paragraph 1]

[ä¸­æ–‡ç¿»è¯‘æ®µè½ 1]

---

> [English paragraph 2]

[ä¸­æ–‡ç¿»è¯‘æ®µè½ 2]

---

### ðŸ“š é‡ç‚¹è¯æ±‡ | Key Vocabulary

| è¯æ±‡ | éŸ³æ ‡ | é‡Šä¹‰ | ä¾‹å¥ |
|------|------|------|------|
| **word** | /phonetic/ | n. è¯æ€§+é‡Šä¹‰ | *Example sentence from article* |
```

### Step 5: Select Vocabulary

For each article, select 5-10 key vocabulary items based on:

1. **Difficulty**: Advanced/academic words (not basic vocabulary)
2. **Usefulness**: High-frequency in business/academic English
3. **Context**: Words that are best learned in context
4. **Variety**: Mix of nouns, verbs, adjectives, phrases

Good vocabulary examples:
- `diatribe` (n. é•¿ç¯‡æŠ¨å‡»)
- `conciliatory` (adj. å’Œè§£çš„)
- `penny-pinching` (adj. ç²¾æ‰“ç»†ç®—çš„)
- `crack the code` (phrase ç ´è§£å¯†ç )

### Step 6: Article Selection Guidelines

When user asks to select articles, choose based on:

1. **Topic diversity**: Different sections (politics, business, tech, culture)
2. **Content richness**: Articles with substantial paragraphs (>500 words)
3. **Learning value**: Rich vocabulary and varied sentence structures
4. **Interest**: Engaging topics that motivate continued reading

## Output Format Options

### Full Translation (Default)
- Every paragraph translated
- Complete vocabulary list
- Best for intensive study

### Summary Mode
- Key paragraphs only
- Extended vocabulary (10-15 words)
- Best for review/overview

### Vocabulary Focus
- Minimal translation
- Expanded vocabulary (15-20 words)
- Multiple example sentences per word
- Best for vocabulary building

## Quality Checklist

Before finalizing output, verify:

- [ ] Paragraphs properly merged (no mid-sentence breaks)
- [ ] Translations accurate and natural
- [ ] Vocabulary includes phonetics
- [ ] Example sentences are from original text
- [ ] Markdown renders correctly
- [ ] File saved to `/mnt/user-data/outputs/`

## Common Publication Patterns

| Publication | Article Separator | Section Headers |
|-------------|-------------------|-----------------|
| The Economist | URL markers | Leaders, Briefing, Business, etc. |
| The New Yorker | Author bylines | Comment, Profiles, Fiction, etc. |
| The Atlantic | --- dividers | Ideas, Politics, Culture, etc. |
| Wired | Author bylines | Ideas, Gear, Science, etc. |
| Time | Page breaks | Nation, World, Ideas, etc. |
| HBR | Article titles | Features, Ideas, Case Studies |

## Tips for Better Results

1. **Ask user preference**: Number of articles, topics of interest
2. **Preview before translating**: Show article list for selection
3. **Batch processing**: Process multiple articles efficiently
4. **Preserve formatting**: Keep emphasis, lists, quotes from original
